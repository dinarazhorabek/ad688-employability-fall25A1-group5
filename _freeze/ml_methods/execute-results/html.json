{
  "hash": "dc3de8009055d2fdcc0292d3da709d64",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Machine Learning Models\"\nsubtitle: \"Modeling the Impact of Industry Gender Composition on Salaries\"\nbibliography: references.bib\ncsl: csl/econometrica.csl\nformat:\n  html:\n    toc: true\n    code-fold: false\n    code-tools: true\n---\n\n<div class=\"card reveal\">\n\n## Overview\nThis analysis examines how industry-level gender dominance relates to advertised salaries across job postings. To incorporate this factor into our models, we assigned each NAICS 2-digit industry code to one of three gender representation categories based on U.S. labor statistics:\n\n- **Male-dominated**  \n- **Mixed**  \n- **Female-dominated**\n\nThese categories reflect broad workforce participation trends across major sectors. Male-dominated sectors typically include labor-intensive industries such as construction and transportation, while female-dominated sectors include health care, education, and administrative or professional services. Mixed sectors show more balanced gender representation or significant role-based variation.\n\n### Integration into Modeling\n\nThese three groups were then encoded numerically as:\n\n- `0` → Male-dominated  \n- `1` → Mixed  \n- `2` → Female-dominated  \n\nThis encoding allows the gender composition of industries to be used directly as a structured feature inside regression and machine learning models.\n\nBy examining salary differences across these groups—while controlling for experience requirements, employment type, remote status, staffing-company involvement, and geographic factors—we evaluate whether certain industry gender compositions correspond to systematically higher or lower advertised wages within the professional and technical job postings present in our dataset.\n\n::: {#ebea495a .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\nlightcast_jp = pd.read_csv(\"data/lightcast_gender.csv\",low_memory=False)\n\ngender_encoding = {\n    \"Male-dominated\": 0,\n    \"Mixed\": 1,\n    \"Female-dominated\": 2,\n}\nlightcast_jp[\"GENDER_DOMINANCE_CODE\"] = lightcast_jp[\"GENDER_DOMINANCE\"].map(gender_encoding)\n```\n:::\n\n\n</div>\n\n---\n\n<div class=\"card reveal\">\n\n## Linear Regression\nThe goal of this model is to answer the question: \n\n> How does the gender dominance of an industry affect the offered salary in job postings?\n\nWe trained a linear regression model using the following features:\n\n- Gender dominance\n- Years of Experience\n- Employment type\n- Remote type\n- Internship indicator\n- Staffing company indicator\n- State\n- NAICS code\n\n::: {#7155b230 .cell execution_count=2}\n``` {.python .cell-code}\nfeatures = [\"SALARY\", \"GENDER_DOMINANCE_CODE\", \"MIN_YEARS_EXPERIENCE\", \"EMPLOYMENT_TYPE\", \"REMOTE_TYPE\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"STATE_NAME\", \"NAICS_2022_2\"]\n\n# print(lightcast_jp[features].isna().sum())\n\ndf_model = lightcast_jp[features]\n# df_model.isna().sum()\n\ndf_model = pd.get_dummies(\n    df_model,\n    columns=[\"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"STATE_NAME\"],\n    drop_first=True\n)\n```\n:::\n\n\nAfter preparing the dataset and encoding categorical features, we trained a linear regression model using an 80/20 train–test split.    \nThe coefficient for GENDER_DOMINANCE represents the expected change in salary when moving from one dominance group to the next (male → mixed → female).\n\n### Model Training\n\n::: {#58c56c28 .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nX = df_model.drop(\"SALARY\", axis=1)\ny = df_model[\"SALARY\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=79)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ncoef = model.coef_[ list(X.columns).index(\"GENDER_DOMINANCE_CODE\") ]\nprint(\"Salary change per category step:\", coef)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSalary change per category step: -6998.672990522361\n```\n:::\n:::\n\n\nMoving from a male-dominated to a mixed industry is associated with an average salary decrease of about $7K.     \nMoving from mixed to female-dominated shows an additional decrease of roughly the same magnitude.\n\n### Model Performance Evaluation\nTo assess the performance of the linear regression model, we compute the R² score using the test dataset. Our model explains approximately 24.3% of the variation in advertised salaries. Meaning that the model captures some underlying structure—especially differences driven by experience, industry, and location—but much of the salary variation remains unexplained under a linear framework.\n\n::: {#65821eab .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.metrics import r2_score\n\ny_pred_lr = model.predict(X_test)\nlr_r2 = r2_score(y_test, y_pred_lr)\nprint(\"R²:\", lr_r2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR²: 0.24315688917716083\n```\n:::\n:::\n\n\n### Predicted Salary by Dominance Group\n\nUsing the average job posting profile in our dataset, we generated predicted salaries for each gender dominance category. The results show a **downward trend in salary as industries become more female-dominated**, even after controlling for experience, employment type, remote status, staffing firm involvement, and state-level differences. In other words, job postings in male-dominated industries are associated with higher advertised salaries, while female-dominated sectors tend to offer lower salaries for otherwise comparable postings in our dataset.\n\nRather than a universal labor-market pattern, the results reflect:\n\n> A salary premium associated with male-dominated technical and analytical job clusters represented in our dataset, not necessarily a generalizable pattern across the entire U.S. workforce.\n\nThis contextual caveat helps ensure the analysis is interpreted correctly without overstating conclusions beyond the scope of the available data.\n\n::: {#d7f04910 .cell execution_count=5}\n``` {.python .cell-code}\nbase = X_train.mean().copy()\n\npred = {}\nfor group_code in [0, 1, 2]:\n    base[\"GENDER_DOMINANCE_CODE\"] = group_code\n    pred[group_code] = model.predict(base.to_frame().T)[0]\n\nmerged = pd.DataFrame({\n    \"GENDER_DOMINANCE_CODE\": list(pred.keys()),\n    \"PREDICTED_SALARY\": list(pred.values())\n})\nmerged[\"GENDER_DOMINANCE\"] = merged[\"GENDER_DOMINANCE_CODE\"].map({v: k for k, v in gender_encoding.items()})    \nmerged = merged[[\"GENDER_DOMINANCE\", \"GENDER_DOMINANCE_CODE\", \"PREDICTED_SALARY\"]]\nprint(merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   GENDER_DOMINANCE  GENDER_DOMINANCE_CODE  PREDICTED_SALARY\n0    Male-dominated                      0     123564.708984\n1             Mixed                      1     116566.035994\n2  Female-dominated                      2     109567.363003\n```\n:::\n:::\n\n\n</div>\n\n<div class=\"card reveal\">\n\n## Random Forest\nThe Random Forest model is used to capture non-linear relationships between job posting characteristics and advertised salary. Unlike linear regression, which assumes a straight-line effect for each feature, Random Forests build many decision trees and combine their predictions. This allows the model to detect more complex interactions across features such as industry, remote work status, experience requirements, and gender dominance.\n\n### Model Training\nWe specify the number of trees, allow trees to grow to full depth, and set a random seed to ensure reproducible results. Using multiple decision trees makes the model more robust and reduces overfitting.\n\nDuring training, the forest collectively learns how salary varies with experience level, industry code, employment type, remote type, and other factors.\n\n::: {#8c5bfc23 .cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.ensemble import RandomForestRegressor\n\nrf_model = RandomForestRegressor(\n    n_estimators=300,\n    max_depth=None,\n    random_state=79,\n    n_jobs=-1\n)\n\nrf_model.fit(X_train, y_train)\ny_pred_rf = rf_model.predict(X_test)\n```\n:::\n\n\n### Model Performance Evaluation\nWe evaluate the model using two metrics:\n\n- **R²:** Measures how much variance in salary the model explains.\n- **RMSE:** Measures average prediction error in dollar terms.\n\nThe model achieves an R² of approximately 0.44, indicating moderate predictive power given the complexity and noise typical of job posting salary data.\n\n::: {#e346efea .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nrf_r2 = r2_score(y_test, y_pred_rf)\nrf_rmse = mean_squared_error(y_test, y_pred_rf) ** 0.5\n\nprint(f\"R²: {rf_r2:.4f}\")\nprint(f\"RMSE: {rf_rmse:,.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR²: 0.4381\nRMSE: 33,780.16\n```\n:::\n:::\n\n\n### Feature Importance Analysis\nRandom Forest provides an estimate of each feature’s importance based on how much it reduces prediction error across the forest of trees. In our results, experience and industry code are the strongest predictors, while gender dominance plays a smaller but measurable role.\n\n::: {#c8dfa576 .cell execution_count=8}\n``` {.python .cell-code}\nrf_importances = (\npd.Series(rf_model.feature_importances_, index=X.columns)\n.sort_values(ascending=False)\n)\nprint(rf_importances.head(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMIN_YEARS_EXPERIENCE        0.375126\nNAICS_2022_2                0.157024\nREMOTE_TYPE                 0.068725\nGENDER_DOMINANCE_CODE       0.056740\nEMPLOYMENT_TYPE             0.040388\nIS_INTERNSHIP_True          0.025948\nSTATE_NAME_California       0.025122\nCOMPANY_IS_STAFFING_True    0.023374\nSTATE_NAME_Texas            0.014256\nSTATE_NAME_New York         0.013872\ndtype: float64\n```\n:::\n:::\n\n\n### Predicted Salary by Dominance Group\n\nThe Random Forest model shows substantial salary differences across gender-dominance categories. These predictions suggest that male-dominated industries carry a significant salary premium, with advertised salaries nearly $56,000 higher than those in mixed or female-dominated industries. In contrast, the salaries for mixed and female-dominated sectors are almost identical.\n\n::: {#314c6f29 .cell execution_count=9}\n``` {.python .cell-code}\nbase_rf = X_train.mean().copy()\n\npred_rf = {}\nfor group_code in [0, 1, 2]:\n    base_rf[\"GENDER_DOMINANCE_CODE\"] = group_code\n    pred_rf[group_code] = rf_model.predict(base_rf.to_frame().T)[0]\n\nrf_merged = pd.DataFrame({\n\"GENDER_DOMINANCE_CODE\": list(pred_rf.keys()),\n\"PREDICTED_SALARY_RF\": list(pred_rf.values())\n})\nrf_merged[\"GENDER_DOMINANCE\"] = rf_merged[\"GENDER_DOMINANCE_CODE\"].map(\n{v: k for k, v in gender_encoding.items()}\n)\nrf_merged = rf_merged[[\"GENDER_DOMINANCE\", \"GENDER_DOMINANCE_CODE\", \"PREDICTED_SALARY_RF\"]]\nprint(rf_merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   GENDER_DOMINANCE  GENDER_DOMINANCE_CODE  PREDICTED_SALARY_RF\n0    Male-dominated                      0        128001.509402\n1             Mixed                      1         71684.453611\n2  Female-dominated                      2         72021.826390\n```\n:::\n:::\n\n\n</div>\n\n",
    "supporting": [
      "ml_methods_files"
    ],
    "filters": [],
    "includes": {}
  }
}